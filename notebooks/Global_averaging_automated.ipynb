{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic global averaging for each model\n",
    "\n",
    "### to be used if all global averages have to be redone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from scipy.signal import detrend\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import intake\n",
    "import pprint\n",
    "import util \n",
    "import os\n",
    "\n",
    "col_url = \"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\"\n",
    "col = intake.open_esm_datastore(col_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions:\n",
    "def area_weights(lat_bnds, lon_bnds): \n",
    "    # computes exact area weigths assuming earth is a perfect sphere\n",
    "    lowerlats = np.radians(lat_bnds[:,0]); upperlats = np.radians(lat_bnds[:,1])\n",
    "    difflon = np.radians(np.diff(lon_bnds[0,:])) # if the differences in longitudes are all the same\n",
    "    areaweights = difflon*(np.sin(upperlats) - np.sin(lowerlats));\n",
    "    areaweights /= areaweights.mean()\n",
    "    return areaweights # list of weights, of same dimension as latitude\n",
    "\n",
    "# function copied from: http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "def leap_year(year, calendar='standard'):\n",
    "    \"\"\"Determine if year is a leap year\"\"\"\n",
    "    leap = False\n",
    "    if ((calendar in ['standard', 'gregorian',\n",
    "        'proleptic_gregorian', 'julian']) and\n",
    "        (year % 4 == 0)):\n",
    "        leap = True\n",
    "        if ((calendar == 'proleptic_gregorian') and\n",
    "            (year % 100 == 0) and\n",
    "            (year % 400 != 0)):\n",
    "            leap = False\n",
    "        elif ((calendar in ['standard', 'gregorian']) and\n",
    "                 (year % 100 == 0) and (year % 400 != 0) and\n",
    "                 (year < 1583)):\n",
    "            leap = False\n",
    "    return leap\n",
    "\n",
    "# function copied from: http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "def get_dpm(time, calendar='standard'):\n",
    "    \"\"\"\n",
    "    return a array of days per month corresponding to the months provided in `months`\n",
    "    \"\"\"\n",
    "    month_length = np.zeros(len(time), dtype=np.int)\n",
    "\n",
    "    cal_days = dpm[calendar]\n",
    "\n",
    "    for i, (month, year) in enumerate(zip(time.month, time.year)):\n",
    "        month_length[i] = cal_days[month]\n",
    "        if leap_year(year, calendar=calendar) and month == 2:\n",
    "            month_length[i] += 1\n",
    "    return month_length\n",
    "\n",
    "# days per month:\n",
    "dpm = {'noleap': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'julian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31], ##### I think this should be correct\n",
    "       'proleptic_gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       '360_day': [0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n",
    "      }\n",
    "\n",
    "def compute_day_weights(ds, calendar = 'noleap', first_month = 1): # new function\n",
    "    month_length = xr.DataArray(get_dpm((ds.time.to_index()), calendar=ds_calendar), coords=[ds.time], name='month_length')\n",
    "    \n",
    "    ##### This code is only tested for noleap so far #####\n",
    "    if first_month == 1:\n",
    "        norm_by_annual = month_length.groupby('time.year').mean('time') # make annual mean\n",
    "        norm_by_monthly = np.concatenate([np.tile(norm_by_annual.values[i], 12) for i in range(len(norm_by_annual.values))])\n",
    "    else: \n",
    "        norm_by_annual = np.array([month_length[i*12:(i+1)*12].mean() for i in range(int(len(month_length)/12))])\n",
    "        norm_by_monthly = np.concatenate([np.tile(norm_by_annual[i], 12) for i in range(len(norm_by_annual))])\n",
    "        \n",
    "    weights = month_length/norm_by_monthly\n",
    "    # normalized to have mean 1\n",
    "    return weights \n",
    "\n",
    "def calendar_check(model):\n",
    "    # Time formats for piControl, found from manual check:\n",
    "    if model in ['TaiESM1', 'BCC-CSM2-MR', 'BCC-ESM1', 'CAMS-CSM1-0', 'CAS-ESM2-0', 'FGOALS-f3-L', 'FGOALS-g3', 'CanESM5', 'CanESM5-CanOE', 'E3SM-1-0', 'E3SM-1-1', 'E3SM-1-1-ECA', 'FIO-ESM-2-0', 'INM-CM4-8', 'INM-CM5-0', 'GISS-E2-1-G', 'GISS-E2-1-G-CC', 'GISS-E2-1-H', 'GISS-E2-2-G', 'CESM2', 'CESM2-FV2', 'CESM2-WACCM', 'CESM2-WACCM-FV2', 'NorCPM1', 'NorESM1-F', 'NorESM2-LM', 'NorESM2-MM', 'GFDL-CM4', 'SAM0-UNICON', 'GFDL-ESM4', 'CIESM', 'MCM-UA-1-0']:\n",
    "        ds_calendar = 'noleap'\n",
    "    elif model in ['EC-Earth3', 'CNRM-CM6-1', 'IPSL-CM6A-LR', 'MIROC-ES2L', 'MIROC6', 'NESM3']: # 'IPSL-CM6A-LR':'piClim-4xCO2','piClim-control' says noleap calendar\n",
    "        ds_calendar = 'gregorian'\n",
    "    elif model in ['AWI-CM-1-1-MR', 'AWI-ESM-1-1-LR', 'EC-Earth3-Veg', 'EC-Earth3-Veg-LR', 'ACCESS-ESM1-5', 'ACCESS-CM2', 'MPI-ESM-1-2-HAM', 'MPI-ESM1-2-LR', 'MPI-ESM1-2-HR', 'EC-Earth3-LR']:\n",
    "        ds_calendar = 'proleptic_gregorian'\n",
    "    elif model in ['UKESM1-0-LL', 'HadGEM3-GC31-LL', 'HadGEM3-GC31-MM', 'CNRM-ESM2-1', 'KACE-1-0-G', 'MRI-ESM2-0']:\n",
    "        ds_calendar = '360_day'\n",
    "        if model in ['CNRM-ESM2-1', 'MRI-ESM2-0']:\n",
    "            print('piControl is 360_day, the other experiments unknown')\n",
    "    elif model in ['IITM-ESM']:\n",
    "        ds_calendar = 'julian'\n",
    "    elif model in ['CNRM-CM6-1-HR', 'EC-Earth3', 'EC-Earth3-LR']:\n",
    "        #ds_calendar = 'datetime64'\n",
    "        print('not 100% sure what calendar this model has, but a guess is made based on other models from same institution')\n",
    "        if model in ['CNRM-CM6-1-HR']:\n",
    "            print('calendar is likely gregorian')\n",
    "            ds_calendar = 'gregorian'\n",
    "    return ds_calendar\n",
    "\n",
    "def exp_list(model):\n",
    "    if model in ['ACCESS-CM2', 'ACCESS-ESM1-5', 'GFDL-ESM4', 'MPI-ESM1-2-LR', 'NorESM2-MM', 'UKESM1-0-LL']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585', 'piClim-4xCO2', 'piClim-control']\n",
    "    elif model in ['CNRM-ESM2-1']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'historical', 'ssp245', 'ssp370', 'ssp585', 'piClim-4xCO2', 'piClim-control']\n",
    "    elif model in ['AWI-CM-1-1-MR', 'BCC-CSM2-MR', 'CAMS-CSM1-0', 'CNRM-CM6-1-HR', 'INM-CM4-8', 'INM-CM5-0', 'MIROC-ES2L', 'MPI-ESM1-2-HR']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "    elif model in ['AWI-ESM-1-1-LR', 'E3SM-1-1', 'E3SM-1-1-ECA', 'GISS-E2-1-G-CC', 'MPI-ESM-1-2-HAM', 'NorCPM1']:\n",
    "        experiments = ['piControl', 'historical']\n",
    "    elif model in ['BCC-ESM1']:\n",
    "        experiments = ['piControl','abrupt-4xCO2', 'historical', 'ssp370', 'piClim-control']\n",
    "    elif model in ['CESM2', 'CNRM-CM6-1', 'MRI-ESM2-0']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'abrupt-2xCO2', 'abrupt-0p5xCO2', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585', 'piClim-4xCO2', 'piClim-control']\n",
    "    elif model in ['CanESM5', 'GISS-E2-1-G', 'MIROC6']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'abrupt-2xCO2', 'abrupt-0p5xCO2', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585', 'piClim-4xCO2', 'piClim-control', 'piClim-histall']\n",
    "    elif model in ['CESM2-FV2', 'CESM2-WACCM-FV2', 'IITM-ESM', 'NorESM1-F']:\n",
    "        experiments = ['piControl']\n",
    "    elif model in ['CESM2-WACCM']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585', 'piClim-control']\n",
    "    elif model in ['E3SM-1-0', 'SAM0-UNICON']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'historical']\n",
    "    elif model in ['EC-Earth3', 'HadGEM3-GC31-MM']:\n",
    "        experiments = ['abrupt-4xCO2']\n",
    "    elif model in ['EC-Earth3-Veg', 'TaiESM1']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2']\n",
    "    elif model in ['FGOALS-g3']:\n",
    "        experiments = ['piControl', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "    elif model in ['GFDL-CM4']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'historical', 'ssp245', 'ssp585', 'piClim-4xCO2', 'piClim-control', 'piClim-histall']\n",
    "    elif model in ['GISS-E2-1-H']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'abrupt-2xCO2', 'historical']\n",
    "    elif model in ['GISS-E2-2-G']:\n",
    "        experiments = ['piControl', 'abrupt-2xCO2']\n",
    "    elif model in ['HadGEM3-GC31-LL']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'abrupt-0p5xCO2', 'historical', 'ssp126', 'ssp245', 'ssp585', 'piClim-4xCO2', 'piClim-control']\n",
    "    elif model in ['IPSL-CM6A-LR']:\n",
    "        experiments = ['piControl', 'abrupt-2xCO2', 'abrupt-0p5xCO2', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585', 'piClim-4xCO2', 'piClim-control', 'piClim-histall']\n",
    "    elif model in ['KACE-1-0-G']:\n",
    "        experiments = ['abrupt-4xCO2', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "    elif model in ['NESM3']:\n",
    "        experiments = ['abrupt-4xCO2','historical']\n",
    "    elif model in ['NorESM2-LM']:\n",
    "        experiments = ['piControl', 'abrupt-4xCO2', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585', 'piClim-4xCO2', 'piClim-control', 'piClim-histall']\n",
    "    return experiments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNRM-CM6-1\n",
      "gregorian calendar according to the function calendar_check\n",
      "['piControl', 'abrupt-4xCO2', 'abrupt-2xCO2', 'abrupt-0p5xCO2', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585', 'piClim-4xCO2', 'piClim-control']\n"
     ]
    }
   ],
   "source": [
    "model = 'CNRM-CM6-1'\n",
    "print(model)\n",
    "\n",
    "ds_calendar = calendar_check(model)\n",
    "print(ds_calendar, 'calendar according to the function calendar_check')\n",
    "explist = exp_list(model)\n",
    "print(explist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r1i1p1f2\n",
      "gregorian\n",
      "piControl r1i1p1f2\n",
      "gregorian calendar\n",
      "hours since 1850-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r1i1p1f2\n",
      "r2i1p1f2\n",
      "r3i1p1f2\n",
      "r4i1p1f2\n",
      "r5i1p1f2\n",
      "r6i1p1f2\n",
      "gregorian\n",
      "abrupt-4xCO2 r1i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "abrupt-4xCO2 r2i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "abrupt-4xCO2 r3i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "abrupt-4xCO2 r4i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "abrupt-4xCO2 r5i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "abrupt-4xCO2 r6i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r1i1p1f2\n",
      "gregorian\n",
      "abrupt-2xCO2 r1i1p1f2\n",
      "gregorian calendar\n",
      "hours since 1850-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r1i1p1f2\n",
      "gregorian\n",
      "abrupt-0p5xCO2 r1i1p1f2\n",
      "gregorian calendar\n",
      "hours since 1850-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r10i1p1f2\n",
      "r11i1p1f2\n",
      "r12i1p1f2\n",
      "r13i1p1f2\n",
      "r14i1p1f2\n",
      "r15i1p1f2\n",
      "r16i1p1f2\n",
      "r17i1p1f2\n",
      "r18i1p1f2\n",
      "r19i1p1f2\n",
      "r1i1p1f2\n",
      "r20i1p1f2\n",
      "r21i1p1f2\n",
      "r22i1p1f2\n",
      "r23i1p1f2\n",
      "r24i1p1f2\n",
      "r25i1p1f2\n",
      "r26i1p1f2\n",
      "r27i1p1f2\n",
      "r28i1p1f2\n",
      "r29i1p1f2\n",
      "r2i1p1f2\n",
      "r30i1p1f2\n",
      "r3i1p1f2\n",
      "r4i1p1f2\n",
      "r5i1p1f2\n",
      "r6i1p1f2\n",
      "r7i1p1f2\n",
      "r8i1p1f2\n",
      "r9i1p1f2\n",
      "gregorian\n",
      "historical r10i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r11i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r12i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r13i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r14i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r15i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r16i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r17i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r18i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r19i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r1i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r20i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r21i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r22i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r23i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r24i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r25i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r26i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r27i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r28i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r29i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r2i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r30i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r3i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r4i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r5i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r6i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r7i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r8i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "historical r9i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r1i1p1f2\n",
      "r2i1p1f2\n",
      "r3i1p1f2\n",
      "r4i1p1f2\n",
      "r5i1p1f2\n",
      "r6i1p1f2\n",
      "gregorian\n",
      "ssp126 r1i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp126 r2i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp126 r3i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp126 r4i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp126 r5i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp126 r6i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r10i1p1f2\n",
      "r1i1p1f2\n",
      "r2i1p1f2\n",
      "r3i1p1f2\n",
      "r4i1p1f2\n",
      "r5i1p1f2\n",
      "r6i1p1f2\n",
      "r7i1p1f2\n",
      "r8i1p1f2\n",
      "r9i1p1f2\n",
      "gregorian\n",
      "ssp245 r10i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp245 r1i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp245 r2i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp245 r3i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp245 r4i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp245 r5i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp245 r6i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp245 r7i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp245 r8i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp245 r9i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r1i1p1f2\n",
      "r2i1p1f2\n",
      "r3i1p1f2\n",
      "r4i1p1f2\n",
      "r5i1p1f2\n",
      "r6i1p1f2\n",
      "gregorian\n",
      "ssp370 r1i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp370 r2i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp370 r3i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp370 r4i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp370 r5i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp370 r6i1p1f2\n",
      "gregorian calendar\n",
      "hours since 2015-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r1i1p1f2\n",
      "r2i1p1f2\n",
      "r3i1p1f2\n",
      "r4i1p1f2\n",
      "r5i1p1f2\n",
      "r6i1p1f2\n",
      "gregorian\n",
      "ssp585 r1i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp585 r2i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp585 r3i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp585 r4i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp585 r5i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "ssp585 r6i1p1f2\n",
      "gregorian calendar\n",
      "days since 1850-01-01\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r1i1p1f2\n",
      "gregorian\n",
      "piClim-4xCO2 r1i1p1f2\n",
      "gregorian calendar\n",
      "hours since 1850-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "r1i1p1f2\n",
      "gregorian\n",
      "piClim-control r1i1p1f2\n",
      "gregorian calendar\n",
      "hours since 1850-01-16 12:00:00.000000\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if model in ['CNRM-CM6-1', 'CNRM-CM6-1-HR', 'CNRM-ESM2-1', 'IPSL-CM6A-LR']: # French models missing lat_bnds and lon_bnds coordinates\n",
    "    # if computing area-weights from areacella instead:\n",
    "    #area_cat= col.search(source_id = model, variable_id=['areacella'])\n",
    "    area_cat = col.search(experiment_id = 'piControl', source_id = model, variable_id=['areacella'])\n",
    "    area_dset_dict = area_cat.to_dataset_dict(zarr_kwargs={'consolidated': True}, cdf_kwargs={'chunks': {}})\n",
    "\n",
    "    for key in area_dset_dict.keys():\n",
    "        area_ds = area_dset_dict[key]\n",
    "    areas = area_ds['areacella'].values[0,:,0]\n",
    "    norm_areas = areas/areas.mean()\n",
    "\n",
    "for exp in explist:\n",
    "    if model == 'UKESM1-0-LL':\n",
    "        cat = col.search(experiment_id = exp, source_id = model, variable_id=['tas', 'rlut', 'rsut', 'rsdt'], table_id='Amon', institution_id = 'MOHC')\n",
    "        #cat = col.search(experiment_id = exp, source_id = model, variable_id=['tas', 'rlut', 'rsut', 'rsdt'], table_id='Amon', institution_id = 'NIMS-KMA')\n",
    "    if model == 'MPI-ESM1-2-HR': # select institution if there are two groups\n",
    "        cat = col.search(experiment_id = exp, source_id = model, variable_id=['tas', 'rlut', 'rsut', 'rsdt'], table_id='Amon')\n",
    "        #cat = col.search(experiment_id = exp, source_id = model, variable_id=['tas', 'rlut', 'rsut', 'rsdt'], table_id='Amon', institution_id = 'DKRZ') \n",
    "        #cat = col.search(experiment_id = exp, source_id = model, variable_id=['tas', 'rlut', 'rsut', 'rsdt'], table_id='Amon', institution_id = 'DWD') \n",
    "    elif model in ['MPI-ESM1-2-LR', 'IPSL-CM6A-LR', 'MRI-ESM2-0', 'EC-Earth3'] and exp in ['piControl']: # problem when loading more than one member simultaneously, so specify member_id:\n",
    "        cat = col.search(experiment_id = exp, source_id = model, variable_id=['tas', 'rlut', 'rsut', 'rsdt'], table_id='Amon', member_id = 'r2i1p1f1')\n",
    "    else:\n",
    "        cat = col.search(experiment_id = exp, source_id = model, variable_id=['tas', 'rlut', 'rsut', 'rsdt'], table_id='Amon')\n",
    "   \n",
    "    if 'dset_dict' in locals():\n",
    "        del dset_dict\n",
    "    if 'ds_exp' in locals():\n",
    "        del ds_exp\n",
    "    dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True}, cdf_kwargs={'chunks': {}})\n",
    "    #for key in ['CMIP.MOHC.UKESM1-0-LL.historical.Amon.gn']:\n",
    "    for key in dset_dict.keys():\n",
    "        ds_exp = dset_dict[key]\n",
    "        if 'members_sorted' in locals():\n",
    "            del members_sorted\n",
    "        members_sorted = ds_exp.member_id.sortby(ds_exp.member_id)\n",
    "\n",
    "    if model == 'MCM-UA-1-0':\n",
    "        ds_exp = ds_exp.rename({'longitude': 'lon','latitude': 'lat'}) \n",
    "\n",
    "    for member in members_sorted:\n",
    "        print(member.values)\n",
    "        \n",
    "    print(ds_exp.time.encoding['calendar'])\n",
    "\n",
    "    \n",
    "    # loop through members\n",
    "    #for member in [members_sorted.sel(member_id = 'r1i1p1f1')]:\n",
    "    for member in members_sorted:\n",
    "        print(exp, member.values)\n",
    "\n",
    "        ds = ds_exp.sel(member_id = member)\n",
    "\n",
    "        ds_calendar = ds.time.encoding['calendar']\n",
    "        unit = ds.time.encoding['units']\n",
    "        firstmonth = ds_exp.time.to_index().month[0]\n",
    "\n",
    "        print(ds_calendar, 'calendar')\n",
    "        print(unit)\n",
    "        print('first month of dataset is:', firstmonth)\n",
    "\n",
    "        # compute weights for average\n",
    "        if model == 'NorCPM1' and exp == 'historical':\n",
    "            area_w = area_weights(ds.lat_bnds.values[0,:,:], ds.lon_bnds.values)\n",
    "        elif model in ['CNRM-CM6-1', 'CNRM-CM6-1-HR', 'CNRM-ESM2-1', 'IPSL-CM6A-LR']: # French models missing lat_bnds and lon_bnds coordinates\n",
    "            area_w = norm_areas\n",
    "        else:\n",
    "            area_w = area_weights(ds.lat_bnds.values, ds.lon_bnds.values)\n",
    "\n",
    "        day_weights = compute_day_weights(ds, calendar = ds_calendar, first_month = firstmonth)\n",
    "\n",
    "        varlist = ['tas', 'rlut', 'rsut', 'rsdt']\n",
    "\n",
    "        for variable in varlist:\n",
    "            print(variable)\n",
    "            data = ds[variable]\n",
    "\n",
    "            # global average\n",
    "            area_avg = (data.transpose('time', 'lon', 'lat') * area_w).mean(dim=['lon', 'lat'])\n",
    "\n",
    "            # annual average\n",
    "            day_weighted_avg = area_avg*day_weights\n",
    "            if firstmonth == 1:\n",
    "                annualmean = day_weighted_avg.groupby('time.year').mean('time')\n",
    "            else:\n",
    "                annualmean_array = np.array([day_weighted_avg[i*12:(i+1)*12].mean() for i in range(int(len(day_weighted_avg)/12))])\n",
    "                annualmean = xr.DataArray(annualmean_array)\n",
    "\n",
    "            if variable == varlist[0]:\n",
    "                # create dataframe for storing all results\n",
    "                df = pd.DataFrame(annualmean.values, columns = [variable])\n",
    "            else:\n",
    "                df_col = pd.DataFrame(annualmean.values, columns = [variable])\n",
    "                df = pd.merge(df, df_col, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "        filename = model + '_' + exp + '_' + str(member.values) + '_means.txt'\n",
    "        file = os.path.join('../Processed_data/Global_annual_means/', model, exp, filename)\n",
    "        #if member == members_sorted[0]: # create directory for first member\n",
    "        #    os.makedirs(os.path.dirname(file), exist_ok=False)\n",
    "\n",
    "        df.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tas</th>\n",
       "      <th>rlut</th>\n",
       "      <th>rsut</th>\n",
       "      <th>rsdt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>286.137598</td>\n",
       "      <td>238.299692</td>\n",
       "      <td>100.783751</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>286.188018</td>\n",
       "      <td>238.475965</td>\n",
       "      <td>100.803157</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>286.142137</td>\n",
       "      <td>238.226050</td>\n",
       "      <td>100.846087</td>\n",
       "      <td>340.477171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>286.182011</td>\n",
       "      <td>238.352729</td>\n",
       "      <td>100.839983</td>\n",
       "      <td>340.445998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>286.162603</td>\n",
       "      <td>238.450502</td>\n",
       "      <td>100.668853</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>286.187039</td>\n",
       "      <td>238.619295</td>\n",
       "      <td>100.820030</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>286.149362</td>\n",
       "      <td>238.262815</td>\n",
       "      <td>100.926250</td>\n",
       "      <td>340.477171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>286.119548</td>\n",
       "      <td>238.202013</td>\n",
       "      <td>100.868418</td>\n",
       "      <td>340.445998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>286.122439</td>\n",
       "      <td>238.116736</td>\n",
       "      <td>100.829697</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>286.105587</td>\n",
       "      <td>238.233546</td>\n",
       "      <td>100.802455</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>286.170230</td>\n",
       "      <td>238.343156</td>\n",
       "      <td>100.688638</td>\n",
       "      <td>340.477171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>286.157507</td>\n",
       "      <td>238.424461</td>\n",
       "      <td>100.671793</td>\n",
       "      <td>340.445998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>286.116015</td>\n",
       "      <td>238.453053</td>\n",
       "      <td>100.775145</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>286.064106</td>\n",
       "      <td>238.194268</td>\n",
       "      <td>101.008749</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>286.094625</td>\n",
       "      <td>238.287015</td>\n",
       "      <td>100.679435</td>\n",
       "      <td>340.477171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>286.169857</td>\n",
       "      <td>238.258124</td>\n",
       "      <td>101.053629</td>\n",
       "      <td>340.445998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>286.135261</td>\n",
       "      <td>238.340130</td>\n",
       "      <td>101.007682</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>286.172072</td>\n",
       "      <td>238.452953</td>\n",
       "      <td>100.489342</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>286.105437</td>\n",
       "      <td>238.192026</td>\n",
       "      <td>100.868867</td>\n",
       "      <td>340.477171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>286.130504</td>\n",
       "      <td>238.137660</td>\n",
       "      <td>100.967298</td>\n",
       "      <td>340.445998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>286.065283</td>\n",
       "      <td>238.180796</td>\n",
       "      <td>100.857791</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>286.157730</td>\n",
       "      <td>238.440285</td>\n",
       "      <td>100.674190</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>286.154230</td>\n",
       "      <td>238.507120</td>\n",
       "      <td>100.699097</td>\n",
       "      <td>340.477171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>286.153218</td>\n",
       "      <td>238.475597</td>\n",
       "      <td>100.662593</td>\n",
       "      <td>340.445998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>286.116169</td>\n",
       "      <td>238.288703</td>\n",
       "      <td>100.750370</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>286.161103</td>\n",
       "      <td>238.257045</td>\n",
       "      <td>100.694388</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>286.122651</td>\n",
       "      <td>238.372261</td>\n",
       "      <td>100.819255</td>\n",
       "      <td>340.477171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>286.076060</td>\n",
       "      <td>238.100074</td>\n",
       "      <td>100.966485</td>\n",
       "      <td>340.445998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>286.171943</td>\n",
       "      <td>238.251473</td>\n",
       "      <td>100.730256</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>286.121238</td>\n",
       "      <td>238.111419</td>\n",
       "      <td>100.962059</td>\n",
       "      <td>340.445992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tas        rlut        rsut        rsdt\n",
       "0   286.137598  238.299692  100.783751  340.445992\n",
       "1   286.188018  238.475965  100.803157  340.445992\n",
       "2   286.142137  238.226050  100.846087  340.477171\n",
       "3   286.182011  238.352729  100.839983  340.445998\n",
       "4   286.162603  238.450502  100.668853  340.445992\n",
       "5   286.187039  238.619295  100.820030  340.445992\n",
       "6   286.149362  238.262815  100.926250  340.477171\n",
       "7   286.119548  238.202013  100.868418  340.445998\n",
       "8   286.122439  238.116736  100.829697  340.445992\n",
       "9   286.105587  238.233546  100.802455  340.445992\n",
       "10  286.170230  238.343156  100.688638  340.477171\n",
       "11  286.157507  238.424461  100.671793  340.445998\n",
       "12  286.116015  238.453053  100.775145  340.445992\n",
       "13  286.064106  238.194268  101.008749  340.445992\n",
       "14  286.094625  238.287015  100.679435  340.477171\n",
       "15  286.169857  238.258124  101.053629  340.445998\n",
       "16  286.135261  238.340130  101.007682  340.445992\n",
       "17  286.172072  238.452953  100.489342  340.445992\n",
       "18  286.105437  238.192026  100.868867  340.477171\n",
       "19  286.130504  238.137660  100.967298  340.445998\n",
       "20  286.065283  238.180796  100.857791  340.445992\n",
       "21  286.157730  238.440285  100.674190  340.445992\n",
       "22  286.154230  238.507120  100.699097  340.477171\n",
       "23  286.153218  238.475597  100.662593  340.445998\n",
       "24  286.116169  238.288703  100.750370  340.445992\n",
       "25  286.161103  238.257045  100.694388  340.445992\n",
       "26  286.122651  238.372261  100.819255  340.477171\n",
       "27  286.076060  238.100074  100.966485  340.445998\n",
       "28  286.171943  238.251473  100.730256  340.445992\n",
       "29  286.121238  238.111419  100.962059  340.445992"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10a",
   "language": "python",
   "name": "cmip6-201910a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
