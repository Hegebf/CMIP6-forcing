{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute global annual anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import importlib\n",
    "import processing_functions\n",
    "from processing_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find models where we have global annual means, but no anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIO-ESM-2-0   ['ssp585', 'piControl', 'abrupt-4xCO2', 'ssp245', 'historical', '1pctCO2', 'ssp126']\n",
      "KACE-1-0-G   ['ssp585', 'piControl', 'abrupt-4xCO2', 'ssp245', 'historical', '1pctCO2', 'ssp370', 'ssp126']\n"
     ]
    }
   ],
   "source": [
    "model_mean_names = [ f.name for f in os.scandir('../Processed_data/Global_annual_means/') if f.is_dir() and f.name !='.ipynb_checkpoints']\n",
    "model_anom_names = [ f.name for f in os.scandir('../Processed_data/Global_annual_anomalies/') if f.is_dir() and f.name !='.ipynb_checkpoints']\n",
    "\n",
    "no_anoms_yet = set(model_mean_names)-set(model_anom_names)\n",
    "for model in no_anoms_yet:\n",
    "    mean_exp = [ f.name for f in os.scandir('../Processed_data/Global_annual_means/' + model) if f.is_dir() and f.name !='.ipynb_checkpoints']\n",
    "    print(model, ' ', mean_exp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Find models where we have some anomalies, but are missing some experiments/members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NorESM2-LM has no anomalies for {'piClim-4xCO2', 'piClim-control', 'piClim-histall'}\n",
      "ACCESS-ESM1-5 has no anomalies for {'piClim-4xCO2', 'piClim-control'}\n",
      "HadGEM3-GC31-LL has no anomalies for {'piClim-4xCO2', 'piClim-control', 'piClim-histall'}\n",
      "CESM2 has no anomalies for {'piClim-4xCO2', 'piClim-control'}\n",
      "CESM2-WACCM has no anomalies for {'piClim-control'}\n",
      "MPI-ESM1-2-LR has no anomalies for {'piClim-4xCO2', 'piClim-control'}\n",
      "GISS-E2-1-G has no anomalies for {'piClim-4xCO2', 'piClim-control', 'piClim-histall'}\n",
      "CNRM-CM6-1 has no anomalies for {'piClim-4xCO2', 'piClim-control', 'piClim-histall'}\n",
      "EC-Earth3-AerChem has no anomalies for {'piClim-control'}\n",
      "MRI-ESM2-0 has no anomalies for {'piClim-4xCO2', 'piClim-control'}\n",
      "EC-Earth3 has no anomalies for {'piClim-4xCO2', 'piClim-control', 'piClim-histall'}\n",
      "Anomalies not computed for members {'r3i1p1f1'} of EC-Earth3 ssp585\n",
      "Anomalies not computed for members {'r2i1p1f2', 'r10i1p1f2', 'r16i1p1f2', 'r8i1p1f2', 'r27i1p1f2', 'r13i1p1f2', 'r15i1p1f2', 'r21i1p1f2', 'r24i1p1f2', 'r30i1p1f2', 'r4i1p1f2', 'r23i1p1f2', 'r12i1p1f2', 'r1i1p1f2', 'r26i1p1f2', 'r25i1p1f2', 'r28i1p1f2', 'r22i1p1f2', 'r6i1p1f2', 'r18i1p1f2', 'r17i1p1f2', 'r20i1p1f2', 'r7i1p1f2', 'r29i1p1f2', 'r19i1p1f2'} of EC-Earth3 ssp245\n",
      "IPSL-CM6A-LR has no anomalies for {'piClim-4xCO2', 'piClim-control', 'piClim-histall'}\n",
      "ACCESS-CM2 has no anomalies for {'piClim-4xCO2', 'piClim-control'}\n",
      "MIROC6 has no anomalies for {'piClim-4xCO2', 'piClim-control', 'piClim-histall'}\n",
      "BCC-ESM1 has no anomalies for {'piClim-control'}\n",
      "MPI-ESM-1-2-HAM has no anomalies for {'piClim-control'}\n",
      "GFDL-ESM4 has no anomalies for {'piClim-4xCO2', 'piClim-control'}\n",
      "UKESM1-0-LL has no anomalies for {'piClim-4xCO2', 'piClim-control'}\n",
      "GFDL-CM4 has no anomalies for {'piClim-4xCO2', 'piClim-control', 'piClim-histall'}\n",
      "CanESM5 has no anomalies for {'piClim-4xCO2', 'piClim-control', 'piClim-histall'}\n",
      "CNRM-ESM2-1 has no anomalies for {'piClim-4xCO2', 'piClim-control'}\n",
      "TaiESM1 has no anomalies for {'piClim-control'}\n",
      "NorESM2-MM has no anomalies for {'piClim-4xCO2', 'piClim-control'}\n",
      "Anomalies not computed for members {'r30i1p1f2', 'r29i1p1f2', 'r26i1p1f2', 'r27i1p1f2', 'r28i1p1f2'} of MIROC-ES2L historical\n",
      "Anomalies not computed for members {'r30i1p1f2', 'r29i1p1f2', 'r26i1p1f2', 'r27i1p1f2', 'r28i1p1f2'} of MIROC-ES2L ssp245\n"
     ]
    }
   ],
   "source": [
    "for model in model_anom_names:\n",
    "    #print(model)\n",
    "    mean_exp = [ f.name for f in os.scandir('../Processed_data/Global_annual_means/' + model) if f.is_dir() and f.name not in ['.ipynb_checkpoints', '.DS_Store']]\n",
    "    anom_exp = [ f.name for f in os.scandir('../Processed_data/Global_annual_anomalies/' + model) if f.is_dir() and f.name not in ['.ipynb_checkpoints', '.DS_Store']]\n",
    "    diff = set(mean_exp) - set(anom_exp)\n",
    "    if len(diff)>0:\n",
    "        print(model, 'has no anomalies for', diff)\n",
    "    other_exp = set(mean_exp) - diff\n",
    "    for exp in other_exp: # do we have all members?\n",
    "        # compare number of files in folders\n",
    "        anom_exp_memberfiles = [ f.name for f in os.scandir('../Processed_data/Global_annual_anomalies/' + model + '/' + exp) if f.name not in ['.ipynb_checkpoints', '.DS_Store']]\n",
    "        anom_exp_members = [file.rsplit('_')[2] for file in anom_exp_memberfiles ]\n",
    "        mean_exp_memberfiles = [ f.name for f in os.scandir('../Processed_data/Global_annual_means/' + model + '/' + exp) if f.name not in ['.ipynb_checkpoints', '.DS_Store']]\n",
    "        mean_exp_members = [file.rsplit('_')[2] for file in mean_exp_memberfiles]\n",
    "        diff_members = set(mean_exp_members) - set(anom_exp_members)\n",
    "        if len(diff_members)>0:\n",
    "            print('Anomalies not computed for members', diff_members, 'of', model, exp)\n",
    "\n",
    "# NB: for piClim experiments we don't compute anomalies here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idealised_exp = ['abrupt-4xCO2', 'abrupt-2xCO2', 'abrupt-0p5xCO2', '1pctCO2']\n",
    "hist_exp = ['historical', 'hist-GHG', 'hist-aer', 'hist-nat']\n",
    "ssp_exp = ['ssp119', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "\n",
    "var_list = ['tas', 'rlut', 'rsut', 'rsdt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(processing_functions)\n",
    "from processing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model_mean_names[56]\n",
    "model = 'FIO-ESM-2-0'\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load branch info. Eventual automatic corrections will be printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#branch_time_file = '../Processed_data/Branch_times/' + model + '_branch_times.txt'\n",
    "#table = pd.read_table(branch_time_file,index_col=0, sep = ' ')\n",
    "\n",
    "branch_time_file = '../Processed_data/Branch_times/' + model + '_branch_times.csv'\n",
    "table = pd.read_table(branch_time_file,index_col=0, sep = ',')\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.min_rows', 15)\n",
    "#display(table)\n",
    "pd.set_option('display.max_rows', None)\n",
    "branch_info_corrections(table);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print available experiments and calendar information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = list(table['exp'].unique())\n",
    "print('Available experiments for this model:')\n",
    "for exp in experiments:\n",
    "    exp_df = table.loc[table['exp'] == exp]\n",
    "    print(exp,':', len(exp_df), 'member(s)')\n",
    "    #display(exp_df)\n",
    "\n",
    "model_calendars = find_model_calendars(model)\n",
    "unique_calendars = model_calendars['calendar'].unique()\n",
    "if len(unique_calendars) == 1:\n",
    "    print('All experiments use the calendar', unique_calendars)\n",
    "else:\n",
    "    for calendar in unique_calendars:\n",
    "        ncals = np.multiply(model_calendars['calendar'] == calendar, 1).sum()\n",
    "        print(ncals, 'experiments use the calendar', calendar)\n",
    "\n",
    "#exp = 'piControl'\n",
    "#exp = 'abrupt-4xCO2'\n",
    "#exp = 'abrupt-2xCO2'\n",
    "#exp = 'abrupt-0p5xCO2'\n",
    "#exp = '1pctCO2'\n",
    "\n",
    "#exp = 'historical'\n",
    "#exp = 'hist-GHG'\n",
    "#exp = 'hist-aer'\n",
    "#exp = 'hist-nat'\n",
    "#exp = 'ssp119'\n",
    "#exp = 'ssp126'\n",
    "#exp = 'ssp245'\n",
    "#exp = 'ssp370'\n",
    "#exp = 'ssp585'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all models except EC-Earth3, which is treated at the end of this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importlib.reload(processing_functions)\n",
    "#from processing_functions import *\n",
    "\n",
    "columnames_branchinfo_overview = ['exp', 'member', 'piControl branch time (days)', 'nearest time in table (days)', 'days difference', 'piControl branch time (year)']\n",
    "branchinfo_overview_df = pd.DataFrame(columns = columnames_branchinfo_overview)\n",
    "\n",
    "piControl_path = '../Processed_data/Global_annual_means/' + model + '/piControl/'\n",
    "historical_path = '../Processed_data/Global_annual_means/' + model + '/historical/'\n",
    "\n",
    "#for exp in ['1pctCO2']:\n",
    "for exp in experiments:\n",
    "    if exp[:6] != 'piClim': # we do not want to compute anomalies from these here\n",
    "        exp_path = '../Processed_data/Global_annual_means/' + model + '/' + exp + '/'\n",
    "\n",
    "        exptable = table.loc[table['exp'] == exp]\n",
    "        available_members = exptable['member'].values\n",
    "\n",
    "        for member in available_members:\n",
    "            print('\\n', model, exp, member)\n",
    "            member_df = exptable.loc[exptable['member'] == member]\n",
    "            member_calendar = find_member_calendar(model, exp, member)\n",
    "\n",
    "            # load exp data\n",
    "            exp_filename = model + '_' + exp + '_' + member + '_means.csv'\n",
    "            exp_data = pd.read_table(exp_path + exp_filename, index_col=0, sep = ',')\n",
    "            if np.isnan(exp_data).values.any():\n",
    "                print('Warning: data contain NaN')\n",
    "            exp_years = exp_data.index.values\n",
    "            if len(str(exp_years[0]))>4:\n",
    "                # then it contains info about start month too,\n",
    "                # because experiment does not start in january\n",
    "                exp_years = [str(yr)[:4] for yr in exp_years] # this code is not tested yet\n",
    "            exp_start_year = exp_years[0]\n",
    "            exp_len = len(exp_years)\n",
    "\n",
    "            if exp == 'piControl':\n",
    "                piControl_member = member\n",
    "            elif exp in idealised_exp or exp in hist_exp: # branches from piControl\n",
    "                branch_time_days = member_df['branch_time_in_parent'].values[0]\n",
    "                piControl_member = member_df['parent_variant_id'].values[0] \n",
    "                yearstr = member_df['parent_time_units'].values[0][11:15]\n",
    "                if '-' in yearstr: # happens for TaiESM1\n",
    "                    yearstr = yearstr[:-1]\n",
    "                piControl_timeunit_start_year = int(yearstr)\n",
    "            elif exp in ssp_exp: # branches from historical\n",
    "                # find historical parent member \n",
    "                parent_member = member_df['parent_variant_id'].values[0]\n",
    "                parent_table = table.loc[table['exp'] == 'historical']\n",
    "                parent_df = parent_table.loc[parent_table['member'] == parent_member]\n",
    "                piControl_timeunit_start_year = int(parent_df['parent_time_units'].values[0][11:15])\n",
    "\n",
    "                # find first year of historical parent (usually 1850)\n",
    "                historical_parent_filename = model + '_historical_' + parent_member + '_means.csv'\n",
    "                historical_parent_data = pd.read_table(historical_path + historical_parent_filename, index_col=0, sep = ',')\n",
    "                first_year_historical_parent = historical_parent_data.index.values[0]\n",
    "                # check branch for historical parent only\n",
    "                branch_time_days = parent_df['branch_time_in_parent'].values[0]\n",
    "                piControl_member = parent_df['parent_variant_id'].values[0]\n",
    "\n",
    "            # load piControl values. \n",
    "            piControl_filename = model + '_piControl_' + piControl_member + '_means.csv'\n",
    "            piControl_data = pd.read_table(piControl_path + piControl_filename, index_col=0, sep = ',')\n",
    "            if np.isnan(piControl_data).values.any():\n",
    "                print('Warning: piControl data contain NaN')\n",
    "            piControl_years = piControl_data.index.values\n",
    "            piControl_start_year = piControl_years[0]\n",
    "\n",
    "            if exp == 'piControl':\n",
    "                corr_piControl_years = piControl_years\n",
    "            else:\n",
    "                if model in ['NESM3']:\n",
    "                    piControl_timeunit_start_year = 500 # probably, since this is when piControl starts\n",
    "                    \n",
    "                print('piControl_start_year', piControl_start_year)\n",
    "                print('piControl_timeunit_start_year', piControl_timeunit_start_year)\n",
    "                piControl_start_diff = piControl_start_year - piControl_timeunit_start_year\n",
    "                if piControl_start_year != piControl_timeunit_start_year:\n",
    "                    print('Note: piControl starts', piControl_start_diff, 'years after its time unit starts')\n",
    "                    #piControl_timeunit_start_year = piControl_timeunit_correction(model, exp, member, piControl_timeunit_start_year, piControl_start_year)\n",
    "\n",
    "                if model == 'CanESM5':\n",
    "                    len_days_table = 6000 # since piControl starts a long time after its time unit starts\n",
    "                else:\n",
    "                    len_days_table = 1500\n",
    "                days_table = np.append([0],np.cumsum(dpy(piControl_timeunit_start_year,piControl_timeunit_start_year+len_days_table, member_calendar)))    \n",
    "                # find index of element closest to branch_time_days:\n",
    "                years_since_piControl_timeunit_start = (np.abs(days_table - branch_time_days)).argmin()\n",
    "                years_since_piControl_start = years_since_piControl_timeunit_start - piControl_start_diff\n",
    "\n",
    "                print('years_since_piControl_start = ', years_since_piControl_start)\n",
    "                #print('branch_time_days', branch_time_days)\n",
    "                #print('nearest_time_in_table', days_table[years_since_piControl_start])\n",
    "                #print('days difference:', days_table[years_since_piControl_timeunit_start] - branch_time_days)\n",
    "                #print('differences not equal to 0 indicate wrong calendar assumptions or branch dates not equal to the start of a new year')\n",
    "\n",
    "                years_since_piControl_start = branch_time_correction(model, exp, member, branch_time_days, piControl_timeunit_start_year, piControl_start_year, years_since_piControl_start)\n",
    "                # write function to correct this for some models\n",
    "\n",
    "                piControl_branch_year = piControl_start_year + years_since_piControl_start\n",
    "\n",
    "                # collect info in overview table:\n",
    "                exp_branchinfo_df = pd.DataFrame([[exp, member, branch_time_days, days_table[years_since_piControl_timeunit_start], days_table[years_since_piControl_timeunit_start] - branch_time_days, piControl_branch_year]], columns = columnames_branchinfo_overview)\n",
    "                branchinfo_overview_df = pd.concat([branchinfo_overview_df, exp_branchinfo_df], ignore_index = True)\n",
    "\n",
    "                if exp in idealised_exp or exp in hist_exp:\n",
    "                    corr_piControl_years = piControl_branch_year + np.arange(exp_len) \n",
    "                elif exp in ssp_exp:\n",
    "                    years_since_piControl_branch = exp_years - first_year_historical_parent\n",
    "                    corr_piControl_years = piControl_branch_year + years_since_piControl_branch #np.arange(165,251)\n",
    "\n",
    "            # Anomalies and piControl_linfit should have the same size and time index as exp_data\n",
    "            # therefore we just copy, and then overwrite the values\n",
    "            anomalies = exp_data.copy(deep=True)\n",
    "            piControl_linfit = exp_data.copy(deep=True)\n",
    "            for var in var_list:\n",
    "                # make linear fit to all piControl years\n",
    "                p1 = np.polyfit(piControl_years, piControl_data[var], 1)\n",
    "\n",
    "                # make linear fit\n",
    "                if set(corr_piControl_years).issubset(set(piControl_years)):\n",
    "                    # then all corr_piControl_years are available\n",
    "                    piControl_linfit[var] = np.polyval(p1,corr_piControl_years)\n",
    "                else:\n",
    "                    # extend the linear fit outside the range of the original piControl years\n",
    "                    corr_piControl_years_ = list(set(corr_piControl_years).union(set(piControl_years)))\n",
    "                    piControl_linfit[var] = np.polyval(p1,corr_piControl_years)\n",
    "\n",
    "                anomalies[var] = exp_data[var] - piControl_linfit[var]\n",
    "\n",
    "            plot_all_absolute_values(exp_data, piControl_linfit, corr_piControl_years,\\\n",
    "                                     piControl_data, text_str = model + '\\n' + exp + '\\n' + member)\n",
    "            #plot_anomalies(anomalies)\n",
    "            #save_anomalies(anomalies, model, exp, member)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the findings in the table below look reasonable, or if there may be branch info errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('piControl_start_year =',piControl_start_year)\n",
    "print('piControl_timeunit_start_year =',piControl_timeunit_start_year)\n",
    "pd.set_option('display.max_rows', None)\n",
    "branchinfo_overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with model metadata branch info\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code changed specifically for EC-Earth3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_branch_time_file = '../Processed_data/Branch_times/EC-Earth3-Veg_branch_times.csv'\n",
    "veg_table = pd.read_table(veg_branch_time_file,index_col=0, sep = ',')\n",
    "pd.set_option('display.max_rows', None)\n",
    "branch_info_corrections(veg_table);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(processing_functions)\n",
    "from processing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columnames_branchinfo_overview = ['exp', 'member', 'piControl branch time (days)', 'nearest time in table (days)', 'days difference', 'piControl branch time (year)']\n",
    "branchinfo_overview_df = pd.DataFrame(columns = columnames_branchinfo_overview)\n",
    "\n",
    "piControl_path = '../Processed_data/Global_annual_means/' + model + '/piControl/'\n",
    "historical_path = '../Processed_data/Global_annual_means/' + model + '/historical/'\n",
    "\n",
    "piControl_parents_lens_path = '../Processed_data/Global_annual_means/EC-Earth3-Veg/piControl/'\n",
    "historical_parents_lens_path = '../Processed_data/Global_annual_means/EC-Earth3-Veg/historical/'\n",
    "\n",
    "for exp in ['ssp585']:\n",
    "#for exp in ['historical']:\n",
    "#for exp in ['piControl', '1pctCO2', 'abrupt-4xCO2']:\n",
    "#for exp in experiments:\n",
    "    if exp[:6] != 'piClim': # we do not want to compute anomalies from these here\n",
    "        exp_path = '../Processed_data/Global_annual_means/' + model + '/' + exp + '/'\n",
    "\n",
    "        exptable = table.loc[table['exp'] == exp]\n",
    "        available_members = exptable['member'].values\n",
    "        print(available_members)\n",
    "        for member in available_members:\n",
    "            if member[-2:] == 'f2':\n",
    "                print('member', member, 'skipped due to uncerain parent information')\n",
    "            elif member == 'r3i1p1f1' and exp in ssp_exp:\n",
    "                print('member', member, 'skipped due to error in historical parent file(s)')\n",
    "                continue\n",
    "            else:\n",
    "                r_value = int(member.split(\"r\")[1].split(\"i\")[0])\n",
    "\n",
    "                print('\\n', model, exp, member)\n",
    "                member_df = exptable.loc[exptable['member'] == member]\n",
    "                member_calendar = find_member_calendar(model, exp, member)\n",
    "\n",
    "                # load exp data\n",
    "                exp_filename = model + '_' + exp + '_' + member + '_means.csv'\n",
    "                exp_data = pd.read_table(exp_path + exp_filename, index_col=0, sep = ',')\n",
    "                if np.isnan(exp_data).values.any():\n",
    "                    print('Warning: data contain NaN')\n",
    "                exp_years = exp_data.index.values\n",
    "                if len(str(exp_years[0]))>4:\n",
    "                    # then it contains info about start month too,\n",
    "                    # because experiment does not start in january\n",
    "                    exp_years = [str(yr)[:4] for yr in exp_years] # this code is not tested yet\n",
    "                exp_start_year = exp_years[0]\n",
    "                exp_len = len(exp_years)\n",
    "\n",
    "                if r_value > 100: # we are in the LENS\n",
    "                    if exp in ssp_exp:\n",
    "                        # first: EC-Earth3 historical parent:\n",
    "                        parent_member = member_df['parent_variant_id'].values[0]\n",
    "                        parent_table = table.loc[table['exp'] == 'historical']\n",
    "                        parent_df = parent_table.loc[parent_table['member'] == parent_member]\n",
    "                        member_df = parent_df \n",
    "                        # to be used further in the next if-test, \n",
    "                        # looking at its EC-Earth3-Veg historical parent                        \n",
    "                    if exp == 'historical' or exp in ssp_exp: \n",
    "                        # branch from EC-Earth3-Veg year 1970 (or actually a breed experiment branched from this again)\n",
    "                        # But I don't have these data, and I think we can assume the values are relatively close to those of EC-Earth3-Veg year 1970\n",
    "                        parent_member = member_df['parent_variant_id'].values[0]\n",
    "                        parent_table = veg_table.loc[veg_table['exp'] == 'historical']\n",
    "                        parent_df = parent_table.loc[parent_table['member'] == parent_member]\n",
    "                        piControl_timeunit_start_year = int(parent_df['parent_time_units'].values[0][11:15])\n",
    "\n",
    "                        # find first year of historical parent (usually 1850)\n",
    "                        historical_parent_filename = 'EC-Earth3-Veg_historical_' + parent_member + '_means.csv'\n",
    "                        historical_parent_data = pd.read_table(historical_parents_lens_path + historical_parent_filename, index_col=0, sep = ',')\n",
    "                        first_year_historical_parent = historical_parent_data.index.values[0]\n",
    "                        # check branch for historical parent\n",
    "                        branch_time_days = parent_df['branch_time_in_parent'].values[0]\n",
    "                        piControl_member = parent_df['parent_variant_id'].values[0]\n",
    "\n",
    "                    # load piControl values. \n",
    "                    piControl_filename = 'EC-Earth3-Veg_piControl_' + piControl_member + '_means.csv'\n",
    "                    piControl_data = pd.read_table(piControl_parents_lens_path + piControl_filename, index_col=0, sep = ',')\n",
    "                    if np.isnan(piControl_data).values.any():\n",
    "                        print('Warning: piControl data contain NaN')\n",
    "                    piControl_years = piControl_data.index.values\n",
    "                    piControl_start_year = piControl_years[0]\n",
    "                else:   \n",
    "                    if exp == 'piControl':\n",
    "                        piControl_member = member\n",
    "                    elif exp in idealised_exp or exp in hist_exp: # branches from piControl\n",
    "                        branch_time_days = float(member_df['branch_time_in_parent'].values[0])\n",
    "                        piControl_member = member_df['parent_variant_id'].values[0] \n",
    "                        yearstr = member_df['parent_time_units'].values[0][11:15]\n",
    "                        if '-' in yearstr: # happens for TaiESM1\n",
    "                            yearstr = yearstr[:-1]\n",
    "                        piControl_timeunit_start_year = int(yearstr)\n",
    "                    elif exp in ssp_exp: # branches from historical\n",
    "                        # find historical parent member \n",
    "                        parent_member = member_df['parent_variant_id'].values[0]\n",
    "                        parent_table = table.loc[table['exp'] == 'historical']\n",
    "                        parent_df = parent_table.loc[parent_table['member'] == parent_member]\n",
    "                        piControl_timeunit_start_year = int(parent_df['parent_time_units'].values[0][11:15])\n",
    "\n",
    "                        # find first year of historical parent (usually 1850)\n",
    "                        historical_parent_filename = model + '_historical_' + parent_member + '_means.csv'\n",
    "                        historical_parent_data = pd.read_table(historical_path + historical_parent_filename, index_col=0, sep = ',')\n",
    "                        first_year_historical_parent = historical_parent_data.index.values[0]\n",
    "                        # check branch for historical parent only\n",
    "                        branch_time_days = float(parent_df['branch_time_in_parent'].values[0])\n",
    "                        piControl_member = parent_df['parent_variant_id'].values[0]\n",
    "\n",
    "                    # load piControl values. \n",
    "                    piControl_filename = model + '_piControl_' + piControl_member + '_means.csv'\n",
    "                    piControl_data = pd.read_table(piControl_path + piControl_filename, index_col=0, sep = ',')\n",
    "                    if np.isnan(piControl_data).values.any():\n",
    "                        print('Warning: piControl data contain NaN')\n",
    "                    piControl_years = piControl_data.index.values\n",
    "                    piControl_start_year = piControl_years[0]\n",
    "\n",
    "\n",
    "                if exp == 'piControl':\n",
    "                    corr_piControl_years = piControl_years\n",
    "                else:\n",
    "                    print('piControl_start_year', piControl_start_year)\n",
    "                    print('piControl_timeunit_start_year', piControl_timeunit_start_year)\n",
    "                    piControl_start_diff = piControl_start_year - piControl_timeunit_start_year\n",
    "                    if piControl_start_year != piControl_timeunit_start_year:\n",
    "                        print('Note: piControl starts', piControl_start_diff, 'years after its time unit starts')\n",
    "                        #piControl_timeunit_start_year = piControl_timeunit_correction(model, exp, member, piControl_timeunit_start_year, piControl_start_year)\n",
    "\n",
    "                    len_days_table = 1500\n",
    "                    days_table = np.append([0],np.cumsum(dpy(piControl_timeunit_start_year,piControl_timeunit_start_year+len_days_table, member_calendar)))    \n",
    "                    # find index of element closest to branch_time_days:\n",
    "                    years_since_piControl_timeunit_start = (np.abs(days_table - branch_time_days)).argmin()\n",
    "                    years_since_piControl_start = years_since_piControl_timeunit_start - piControl_start_diff\n",
    "\n",
    "                    print('years_since_piControl_start = ', years_since_piControl_start)\n",
    "\n",
    "                    years_since_piControl_start = branch_time_correction(model, exp, member, branch_time_days, piControl_timeunit_start_year, piControl_start_year, years_since_piControl_start)\n",
    "                    #if branch_time_days == 0:\n",
    "                    #    years_since_piControl_start = 0\n",
    "                    \n",
    "                    piControl_branch_year = piControl_start_year + years_since_piControl_start\n",
    "\n",
    "                    # collect info in overview table:\n",
    "                    exp_branchinfo_df = pd.DataFrame([[exp, member, branch_time_days, days_table[years_since_piControl_timeunit_start], days_table[years_since_piControl_timeunit_start] - branch_time_days, piControl_branch_year]], columns = columnames_branchinfo_overview)\n",
    "                    branchinfo_overview_df = pd.concat([branchinfo_overview_df, exp_branchinfo_df], ignore_index = True)\n",
    "\n",
    "                    if exp in idealised_exp or exp in hist_exp:\n",
    "                        corr_piControl_years = piControl_branch_year + np.arange(exp_len) \n",
    "                    elif exp in ssp_exp:\n",
    "                        years_since_piControl_branch = exp_years - first_year_historical_parent\n",
    "                        corr_piControl_years = piControl_branch_year + years_since_piControl_branch #np.arange(165,251)\n",
    "                        \n",
    "                    if r_value > 100: # we are in the LENS\n",
    "                        if exp == 'historical' or exp in ssp_exp:\n",
    "                            years_since_piControl_branch = exp_years - first_year_historical_parent\n",
    "                            corr_piControl_years = piControl_branch_year + years_since_piControl_branch #np.arange(165,251)\n",
    "\n",
    "\n",
    "                # Anomalies and piControl_linfit should have the same size and time index as exp_data\n",
    "                # therefore we just copy, and then overwrite the values\n",
    "                anomalies = exp_data.copy(deep=True)\n",
    "                piControl_linfit = exp_data.copy(deep=True)\n",
    "                for var in var_list:\n",
    "                    # make linear fit to all piControl years\n",
    "                    p1 = np.polyfit(piControl_years, piControl_data[var], 1)\n",
    "\n",
    "                    # make linear fit\n",
    "                    if set(corr_piControl_years).issubset(set(piControl_years)):\n",
    "                        # then all corr_piControl_years are available\n",
    "                        piControl_linfit[var] = np.polyval(p1,corr_piControl_years)\n",
    "                    else:\n",
    "                        # extend the linear fit outside the range of the original piControl years\n",
    "                        corr_piControl_years_ = list(set(corr_piControl_years).union(set(piControl_years)))\n",
    "                        piControl_linfit[var] = np.polyval(p1,corr_piControl_years)\n",
    "\n",
    "                    anomalies[var] = exp_data[var] - piControl_linfit[var]\n",
    "\n",
    "                plot_all_absolute_values(exp_data, piControl_linfit, corr_piControl_years,\\\n",
    "                                         piControl_data, text_str = model + '\\n' + exp + '\\n' + member)\n",
    "                #plot_anomalies(anomalies)\n",
    "                save_anomalies(anomalies, model, exp, member)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('piControl_start_year =',piControl_start_year)\n",
    "print('piControl_timeunit_start_year =',piControl_timeunit_start_year)\n",
    "pd.set_option('display.max_rows', None)\n",
    "branchinfo_overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CMIP6_hege]",
   "language": "python",
   "name": "conda-env-CMIP6_hege-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
