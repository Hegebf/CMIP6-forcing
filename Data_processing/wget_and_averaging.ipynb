{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute global means for data missing in the cloud by downloading data with wget scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyesgf.search.connection.SearchConnection at 0x7f82ce17d7f0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyesgf.search import SearchConnection\n",
    "from pyesgf.logon import LogonManager\n",
    "import importlib\n",
    "import global_annual_means\n",
    "from global_annual_means import *\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import xarray as xr\n",
    "import tempfile\n",
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "conn = SearchConnection('https://esgf-node.llnl.gov/esg-search', distrib=True, expire_after = datetime.timedelta(0, 10*3600)) \n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogonManager()\n",
    "#lm.logoff()\n",
    "lm.is_logged_on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.logon_with_openid(openid='https://esgf-node.llnl.gov/esgf-idp/openid/hegebeate', password=None)\n",
    "lm.is_logged_on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = ['piControl', 'abrupt-4xCO2', '1pctCO2',\\\n",
    "                   'abrupt-2xCO2', 'abrupt-0p5xCO2',\\\n",
    "                   'historical', 'hist-GHG', 'hist-nat', 'hist-aer',\\\n",
    "                  'ssp119', 'ssp126', 'ssp245', 'ssp370', 'ssp585',\\\n",
    "                  'piClim-control', 'piClim-4xCO2', 'piClim-histall']\n",
    "\n",
    "variable_list = ['tas','rlut','rsut','rsdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files are intially downloaded to the temporary directory where the wget scripts end up:\n",
    "download_dir = '/var/folders/53/fvz76zt55t3fbyz2bxr_l6540000gn/T'\n",
    "# then moved later\n",
    "\n",
    "for exp in experiment_list:\n",
    "#for exp in [experiment_list[11]]:\n",
    "    with open('../Data_availability/GoogleCloud/missing-'+exp+'.json', 'r') as f:\n",
    "         data_dict = json.load(f)\n",
    "    #with open('../Data_availability/GoogleCloud/cloud-buterrors.json', 'r') as f:\n",
    "    #     data_dict = json.load(f)\n",
    "    #if exp in data_dict:\n",
    "    #    data_dict = data_dict[exp]\n",
    "    #    print(exp, data_dict)\n",
    "    #else:\n",
    "    #    continue\n",
    "    print(exp, data_dict)\n",
    "    \n",
    "    #for model in ['EC-Earth3']:\n",
    "    for model in data_dict:\n",
    "        #for member in ['r20i1p1f1']:\n",
    "        for member in data_dict[model]:\n",
    "            filename = model + '_' + exp + '_' + str(member) + '_means.csv'\n",
    "            filepath = os.path.join('../Processed_data/Global_annual_means_csv/', model, exp)\n",
    "            exp_model_dir = download_dir + '/CMIP6_data/' + exp + '_data/' + model\n",
    "            # check if file exists already:\n",
    "            if os.path.isfile(filepath + '/' + filename):\n",
    "                print(exp, model, member, 'global means already exist, so data will not be downloaded')\n",
    "                continue\n",
    "            elif os.path.isdir(exp_model_dir):\n",
    "                print('Folder for putting files in is already created.')\n",
    "                filesindir = [f.name for f in os.scandir(exp_model_dir) if f.name[-3:] =='.nc']\n",
    "                member_files = [file for file in filesindir if member in file]\n",
    "                if len(member_files) > 0:\n",
    "                    print(len(member_files), 'files for', exp, model, member, 'exist')\n",
    "                    counters = {}\n",
    "                    for var in variable_list:\n",
    "                        counters[var] = 0\n",
    "                        for file in member_files: \n",
    "                            if var in file:\n",
    "                                counters[var] += 1\n",
    "                    print(counters)\n",
    "                    #print('New files will not be downloaded')\n",
    "                    #continue\n",
    "                else:\n",
    "                    print('No files for', exp, model, member, 'exist, so they will be downloaded') \n",
    "            else:\n",
    "                print(exp, model, member)\n",
    "\n",
    "            #############\n",
    "            # check if files are already downloaded:\n",
    "            filestr = 'Amon_'+ model + '_' + exp + '_' + member\n",
    "            #if filecheck(filestr, all_ncfiles) is not False:\n",
    "\n",
    "            #ctx = conn.new_context(project='CMIP6', table_id = 'Amon',\\\n",
    "            #       latest=True, source_id = model, replica = False,\\\n",
    "            #       experiment_id=exp, variable=variable_list, variant_label = member)\n",
    "            ctx = conn.new_context(project='CMIP6', table_id = 'Amon',\\\n",
    "                   #latest=True, source_id = model, replica = True, data_node = 'esgf.nci.org.au',\\\n",
    "                   latest=True, source_id = model, data_node = 'esgf.nci.org.au',\\\n",
    "                    experiment_id=exp, variable=variable_list, variant_label = member)\n",
    "\n",
    "            wget_script_content = ctx.get_download_script() \n",
    "            script_path = tempfile.mkstemp(suffix='.sh', prefix='download-')[1]\n",
    "            with open(script_path, \"w\") as writer:\n",
    "                writer.write(wget_script_content)\n",
    "            print(script_path)\n",
    "\n",
    "            # running the script here seems to be slower than running it in the terminal..\n",
    "\n",
    "            #os.chmod(script_path, 0o750)\n",
    "            #download_dir = os.path.dirname(script_path)\n",
    "            #print(download_dir)\n",
    "            #subprocess.check_output(\"{}\".format(script_path), cwd=download_dir)\n",
    "\n",
    "            #############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move files to subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = '/var/folders/53/fvz76zt55t3fbyz2bxr_l6540000gn/T'\n",
    "\n",
    "ncfiles = [f.name for f in os.scandir(download_dir) if f.name[-3:] =='.nc']\n",
    "for file in ncfiles:\n",
    "    filename_parts = file.rsplit(\"_\")\n",
    "    model = filename_parts[2]; exp = filename_parts[3];\n",
    "    subdir = 'CMIP6_data/' + exp + '_data/' + model\n",
    "    if os.path.isdir(download_dir + '/' + subdir) == False:\n",
    "        os.makedirs(download_dir + '/' + subdir)\n",
    "    shutil.move(download_dir + '/' + file, download_dir + '/' + subdir + '/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make global average of data where averages do not exist yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(exp_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "660 files for historical EC-Earth3-AerChem r4i1p1f1 exist: {'tas': 165, 'rlut': 165, 'rsut': 165, 'rsdt': 165}\n",
      "historical EC-Earth3-AerChem r4i1p1f1 : global averaging will be performed\n",
      "proleptic_gregorian\n",
      "Coordinates:\n",
      "  * time      (time) object 1850-01-16 12:00:00 ... 2014-12-16 12:00:00\n",
      "  * lat       (lat) float64 -89.46 -88.77 -88.07 -87.37 ... 88.07 88.77 89.46\n",
      "    lat_bnds  (lat, bnds) float64 dask.array<chunksize=(256, 2), meta=np.ndarray>\n",
      "  * lon       (lon) float64 0.0 0.7031 1.406 2.109 ... 357.2 357.9 358.6 359.3\n",
      "    lon_bnds  (lon, bnds) float64 dask.array<chunksize=(512, 2), meta=np.ndarray>\n",
      "    height    float64 2.0\n",
      "first month of dataset is: 1\n",
      "tas\n",
      "rlut\n",
      "rsut\n",
      "rsdt\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(global_annual_means)\n",
    "from global_annual_means import *\n",
    "\n",
    "#download_dir = '/var/folders/53/fvz76zt55t3fbyz2bxr_l6540000gn/T'\n",
    "download_dir = '/Users/hege-beatefredriksen/Desktop/CMIP6_downloads/'\n",
    "\n",
    "for exp in ['historical']:\n",
    "#for exp in [experiment_list[0]]:\n",
    "#for exp in experiment_list[1:]:\n",
    "    #with open('../Data_availability/GoogleCloud/missing-'+exp+'.json', 'r') as f:\n",
    "    #     data_dict = json.load(f)\n",
    "    #with open('../Data_availability/GoogleCloud/cloud-buterrors.json', 'r') as f:\n",
    "    #     data_dict = json.load(f)\n",
    "    #if exp in data_dict:\n",
    "    #    data_dict = data_dict[exp]\n",
    "    #    print(exp, data_dict)\n",
    "    #else:\n",
    "    #    continue\n",
    "    #print(exp, data_dict)\n",
    "    for model in ['EC-Earth3-AerChem']:\n",
    "    #for model in data_dict:\n",
    "        #if model in ['EC-Earth3']:\n",
    "        #if model in ['ICON-ESM-LR']: \n",
    "        #for member in ['r'+str(r)+'i1p1f1' for r in range(21,50)]:\n",
    "        for member in ['r4i1p1f1']:\n",
    "        #for member in data_dict[model]:\n",
    "            \n",
    "            #if missing_esgf_test(exp, model, member) == True:\n",
    "            #    continue\n",
    "            \n",
    "            #if member in ['r3i1p1f1', 'r20i1p1f1']:\n",
    "            #    continue\n",
    "            filename = model + '_' + exp + '_' + str(member) + '_means.csv'\n",
    "            filepath = os.path.join('../Processed_data/Global_annual_means_csv/', model, exp)\n",
    "            #exp_model_dir = download_dir + '/CMIP6_data/' + exp + '_data/' + model\n",
    "            exp_model_dir = download_dir + exp + '_data/' + model\n",
    "            \n",
    "            # check if files exists already:\n",
    "            if os.path.isdir(exp_model_dir):\n",
    "                print('test')\n",
    "                model_exp_files = [f.name for f in os.scandir(exp_model_dir) if f.name[-3:] =='.nc']\n",
    "                member_files = [file for file in model_exp_files if member in file]\n",
    "                member_paths = [exp_model_dir + '/' + file for file in member_files]\n",
    "                if len(member_files) > 0:\n",
    "\n",
    "                    counters = {}\n",
    "                    for var in variable_list:\n",
    "                        counters[var] = 0\n",
    "                        for file in member_files: \n",
    "                            if var in file:\n",
    "                                counters[var] += 1\n",
    "                    print(len(member_files), 'files for', exp, model, member, 'exist:', counters)\n",
    "                \n",
    "                #if os.path.isfile(filepath + '/' + filename):\n",
    "                #    print(exp, model, member, 'global means already exist, so we will not make new averages')\n",
    "                #    continue\n",
    "\n",
    "                # perform averaging if we have any files to average:\n",
    "                if len(member_paths)>0:\n",
    "                    print(exp, model, member, ': global averaging will be performed')\n",
    "                    first_ds = xr.open_dataset(member_paths[0])\n",
    "                    ds_calendar = first_ds.time.encoding['calendar']\n",
    "                    print(ds_calendar)\n",
    "\n",
    "                    #if member in sepvar_dict_downloadeddata[exp][model]:\n",
    "                    #avg_df = global_average_sepvar_downloadeddata(exp, model, member, member_paths, ds_calendar)\n",
    "                    #else:\n",
    "                    ds = xr.open_mfdataset(member_paths, combine='by_coords', join = 'exact', concat_dim='time', parallel = True, preprocess = preprocess, use_cftime = True)\n",
    "                    # join = 'override' used for:\n",
    "                    # 1pctCO2 EC-Earth3 r3i1p1f1\n",
    "                    # historical NorCPM1 all members\n",
    "                    # beacause of different coordinate values\n",
    "\n",
    "                    #ds = ds.drop_vars('time_bnds')\n",
    "                    print(ds.coords)\n",
    "                    avg_df = global_averaging(ds, calendar = ds_calendar)\n",
    "\n",
    "                    # save dataframe as csv:\n",
    "                    if os.path.isdir(filepath) == False:\n",
    "                        os.makedirs(filepath)\n",
    "                    #avg_df.to_csv(filepath + '/' + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tas</th>\n",
       "      <th>rlut</th>\n",
       "      <th>rsut</th>\n",
       "      <th>rsdt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>287.286910</td>\n",
       "      <td>243.230079</td>\n",
       "      <td>96.678061</td>\n",
       "      <td>340.282561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>287.377374</td>\n",
       "      <td>243.400189</td>\n",
       "      <td>96.870140</td>\n",
       "      <td>340.271686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>287.266519</td>\n",
       "      <td>243.290075</td>\n",
       "      <td>97.280786</td>\n",
       "      <td>340.301725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>287.324943</td>\n",
       "      <td>243.296003</td>\n",
       "      <td>96.755230</td>\n",
       "      <td>340.250529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>287.357155</td>\n",
       "      <td>243.324142</td>\n",
       "      <td>96.957377</td>\n",
       "      <td>340.223416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>287.626921</td>\n",
       "      <td>241.187936</td>\n",
       "      <td>97.737666</td>\n",
       "      <td>340.252578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>287.784426</td>\n",
       "      <td>241.395101</td>\n",
       "      <td>98.537768</td>\n",
       "      <td>340.319855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>287.771948</td>\n",
       "      <td>241.444752</td>\n",
       "      <td>98.377627</td>\n",
       "      <td>340.379602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>287.738657</td>\n",
       "      <td>241.650557</td>\n",
       "      <td>97.808627</td>\n",
       "      <td>340.363818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>287.735538</td>\n",
       "      <td>241.346899</td>\n",
       "      <td>97.465140</td>\n",
       "      <td>340.383479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tas        rlut       rsut        rsdt\n",
       "year                                               \n",
       "1850  287.286910  243.230079  96.678061  340.282561\n",
       "1851  287.377374  243.400189  96.870140  340.271686\n",
       "1852  287.266519  243.290075  97.280786  340.301725\n",
       "1853  287.324943  243.296003  96.755230  340.250529\n",
       "1854  287.357155  243.324142  96.957377  340.223416\n",
       "...          ...         ...        ...         ...\n",
       "2010  287.626921  241.187936  97.737666  340.252578\n",
       "2011  287.784426  241.395101  98.537768  340.319855\n",
       "2012  287.771948  241.444752  98.377627  340.379602\n",
       "2013  287.738657  241.650557  97.808627  340.363818\n",
       "2014  287.735538  241.346899  97.465140  340.383479\n",
       "\n",
       "[165 rows x 4 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df.to_csv(filepath + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CMIP6_hege]",
   "language": "python",
   "name": "conda-env-CMIP6_hege-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
