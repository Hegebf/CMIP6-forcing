{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute global means for data missing in the cloud by downloading data with wget scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyesgf.search.connection.SearchConnection at 0x7f82ce152cc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyesgf.search import SearchConnection\n",
    "from pyesgf.logon import LogonManager\n",
    "import importlib\n",
    "from global_annual_means import *\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import xarray as xr\n",
    "import tempfile\n",
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "conn = SearchConnection('https://esgf-node.llnl.gov/esg-search', distrib=True, expire_after = datetime.timedelta(0, 10*3600)) \n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogonManager()\n",
    "#lm.logoff()\n",
    "lm.is_logged_on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.logon_with_openid(openid='https://esgf-node.llnl.gov/esgf-idp/openid/hegebeate', password=None)\n",
    "lm.is_logged_on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = ['piControl', 'abrupt-4xCO2', '1pctCO2',\\\n",
    "                   'abrupt-2xCO2', 'abrupt-0p5xCO2',\\\n",
    "                   'historical', 'hist-GHG', 'hist-nat', 'hist-aer',\\\n",
    "                  'ssp119', 'ssp126', 'ssp245', 'ssp370', 'ssp585',\\\n",
    "                  'piClim-control', 'piClim-4xCO2', 'piClim-histall']\n",
    "\n",
    "variable_list = ['tas','rlut','rsut','rsdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files are intially downloaded to the temporary directory where the wget scripts end up:\n",
    "download_dir = '/var/folders/53/fvz76zt55t3fbyz2bxr_l6540000gn/T'\n",
    "# then moved later\n",
    "\n",
    "for exp in experiment_list:\n",
    "#for exp in [experiment_list[11]]:\n",
    "    with open('../Data_availability/GoogleCloud/missing-'+exp+'.json', 'r') as f:\n",
    "         data_dict = json.load(f)\n",
    "    #with open('../Data_availability/GoogleCloud/cloud-buterrors.json', 'r') as f:\n",
    "    #     data_dict = json.load(f)\n",
    "    #if exp in data_dict:\n",
    "    #    data_dict = data_dict[exp]\n",
    "    #    print(exp, data_dict)\n",
    "    #else:\n",
    "    #    continue\n",
    "    print(exp, data_dict)\n",
    "    \n",
    "    #for model in ['EC-Earth3']:\n",
    "    for model in data_dict:\n",
    "        #for member in ['r20i1p1f1']:\n",
    "        for member in data_dict[model]:\n",
    "            filename = model + '_' + exp + '_' + str(member) + '_means.csv'\n",
    "            filepath = os.path.join('../Processed_data/Global_annual_means_csv/', model, exp)\n",
    "            exp_model_dir = download_dir + '/CMIP6_data/' + exp + '_data/' + model\n",
    "            # check if file exists already:\n",
    "            if os.path.isfile(filepath + '/' + filename):\n",
    "                print(exp, model, member, 'global means already exist, so data will not be downloaded')\n",
    "                continue\n",
    "            elif os.path.isdir(exp_model_dir):\n",
    "                print('Folder for putting files in is already created.')\n",
    "                filesindir = [f.name for f in os.scandir(exp_model_dir) if f.name[-3:] =='.nc']\n",
    "                member_files = [file for file in filesindir if member in file]\n",
    "                if len(member_files) > 0:\n",
    "                    print(len(member_files), 'files for', exp, model, member, 'exist')\n",
    "                    counters = {}\n",
    "                    for var in variable_list:\n",
    "                        counters[var] = 0\n",
    "                        for file in member_files: \n",
    "                            if var in file:\n",
    "                                counters[var] += 1\n",
    "                    print(counters)\n",
    "                    #print('New files will not be downloaded')\n",
    "                    #continue\n",
    "                else:\n",
    "                    print('No files for', exp, model, member, 'exist, so they will be downloaded') \n",
    "            else:\n",
    "                print(exp, model, member)\n",
    "\n",
    "            #############\n",
    "            # check if files are already downloaded:\n",
    "            filestr = 'Amon_'+ model + '_' + exp + '_' + member\n",
    "            #if filecheck(filestr, all_ncfiles) is not False:\n",
    "\n",
    "            #ctx = conn.new_context(project='CMIP6', table_id = 'Amon',\\\n",
    "            #       latest=True, source_id = model, replica = False,\\\n",
    "            #       experiment_id=exp, variable=variable_list, variant_label = member)\n",
    "            ctx = conn.new_context(project='CMIP6', table_id = 'Amon',\\\n",
    "                   #latest=True, source_id = model, replica = True, data_node = 'esgf.nci.org.au',\\\n",
    "                   latest=True, source_id = model, data_node = 'esgf.nci.org.au',\\\n",
    "                    experiment_id=exp, variable=variable_list, variant_label = member)\n",
    "\n",
    "            wget_script_content = ctx.get_download_script() \n",
    "            script_path = tempfile.mkstemp(suffix='.sh', prefix='download-')[1]\n",
    "            with open(script_path, \"w\") as writer:\n",
    "                writer.write(wget_script_content)\n",
    "            print(script_path)\n",
    "\n",
    "            # running the script here seems to be slower than running it in the terminal..\n",
    "\n",
    "            #os.chmod(script_path, 0o750)\n",
    "            #download_dir = os.path.dirname(script_path)\n",
    "            #print(download_dir)\n",
    "            #subprocess.check_output(\"{}\".format(script_path), cwd=download_dir)\n",
    "\n",
    "            #############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move files to subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = '/var/folders/53/fvz76zt55t3fbyz2bxr_l6540000gn/T'\n",
    "\n",
    "ncfiles = [f.name for f in os.scandir(download_dir) if f.name[-3:] =='.nc']\n",
    "for file in ncfiles:\n",
    "    filename_parts = file.rsplit(\"_\")\n",
    "    model = filename_parts[2]; exp = filename_parts[3];\n",
    "    subdir = 'CMIP6_data/' + exp + '_data/' + model\n",
    "    if os.path.isdir(download_dir + '/' + subdir) == False:\n",
    "        os.makedirs(download_dir + '/' + subdir)\n",
    "    shutil.move(download_dir + '/' + file, download_dir + '/' + subdir + '/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make global average of data where averages do not exist yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = '/var/folders/53/fvz76zt55t3fbyz2bxr_l6540000gn/T'\n",
    "\n",
    "#for exp in [experiment_list[5]]:\n",
    "for exp in experiment_list[1:]:\n",
    "    with open('../Data_availability/GoogleCloud/missing-'+exp+'.json', 'r') as f:\n",
    "         data_dict = json.load(f)\n",
    "    #with open('../Data_availability/GoogleCloud/cloud-buterrors.json', 'r') as f:\n",
    "    #     data_dict = json.load(f)\n",
    "    #if exp in data_dict:\n",
    "    #    data_dict = data_dict[exp]\n",
    "    #    print(exp, data_dict)\n",
    "    #else:\n",
    "    #    continue\n",
    "    #print(exp, data_dict)\n",
    "    for model in data_dict:\n",
    "        #if model in ['EC-Earth3']:\n",
    "        if model in ['ICON-ESM-LR']: \n",
    "            for member in data_dict[model]:\n",
    "                if missing_esgf_test(exp, model, member) == True:\n",
    "                    continue\n",
    "                #if member in ['r3i1p1f1', 'r20i1p1f1']:\n",
    "                #    continue\n",
    "                filename = model + '_' + exp + '_' + str(member) + '_means.csv'\n",
    "                filepath = os.path.join('../Processed_data/Global_annual_means_csv/', model, exp)\n",
    "                exp_model_dir = download_dir + '/CMIP6_data/' + exp + '_data/' + model\n",
    "                \n",
    "                # check if files exists already:\n",
    "                if os.path.isdir(exp_model_dir):\n",
    "                    model_exp_files = [f.name for f in os.scandir(exp_model_dir) if f.name[-3:] =='.nc']\n",
    "                    member_files = [file for file in model_exp_files if member in file]\n",
    "                    member_paths = [exp_model_dir + '/' + file for file in member_files]\n",
    "                    if len(member_files) > 0:\n",
    "\n",
    "                        counters = {}\n",
    "                        for var in variable_list:\n",
    "                            counters[var] = 0\n",
    "                            for file in member_files: \n",
    "                                if var in file:\n",
    "                                    counters[var] += 1\n",
    "                        print(len(member_files), 'files for', exp, model, member, 'exist:', counters)\n",
    "\n",
    "                    if os.path.isfile(filepath + '/' + filename):\n",
    "                        print(exp, model, member, 'global means already exist, so we will not make new averages')\n",
    "                        continue\n",
    "\n",
    "                    # perform averaging if we have any files to average:\n",
    "                    if len(member_paths)>0:\n",
    "                        print(exp, model, member, ': global averaging will be performed')\n",
    "                        first_ds = xr.open_dataset(member_paths[0])\n",
    "                        ds_calendar = first_ds.time.encoding['calendar']\n",
    "                        print(ds_calendar)\n",
    "\n",
    "                        #if member in sepvar_dict_downloadeddata[exp][model]:\n",
    "                        #    avg_df = global_average_sepvar_downloadeddata(exp, model, member, member_paths, ds_calendar)\n",
    "                        #else:\n",
    "                        ds = xr.open_mfdataset(member_paths, combine='by_coords', join = 'exact', concat_dim='time', parallel = True, preprocess = preprocess, use_cftime = True)\n",
    "                        # join = 'override' used for:\n",
    "                        # 1pctCO2 EC-Earth3 r3i1p1f1\n",
    "                        # beacause of different coordinate values\n",
    "                        \n",
    "                        #ds = ds.drop_vars('time_bnds')\n",
    "                        print(ds.coords)\n",
    "                        avg_df = global_averaging(ds, calendar = ds_calendar)\n",
    "\n",
    "                        # save dataframe as csv:\n",
    "                        if os.path.isdir(filepath) == False:\n",
    "                            os.makedirs(filepath)\n",
    "                        avg_df.to_csv(filepath + '/' + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CMIP6_hege]",
   "language": "python",
   "name": "conda-env-CMIP6_hege-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
